{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komalverma04/text_to_image/blob/main/Copy_of_project_text_to_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdebCB49I6Pd"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"StackGAN.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
        "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = '/content/drive/MyDrive/101_ObjectCategories'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DgABvfXI9A3",
        "outputId": "f05a6388-bc85-4d27-f1bd-b7224e75bd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conditioned by the text.\n",
        "def conditioning_augmentation(x):\n",
        "\t\"\"\"The mean_logsigma passed as argument is converted into the text conditioning variable.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The output of the text embedding passed through a FC layer with LeakyReLU non-linearity.\n",
        "\n",
        "\tReturns:\n",
        "\t \tc: The text conditioning variable after computation.\n",
        "\t\"\"\"\n",
        "\tmean = x[:, :128]\n",
        "\tlog_sigma = x[:, 128:]\n",
        "\n",
        "\tstddev = tf.math.exp(log_sigma)\n",
        "\tepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
        "\tc = mean + stddev * epsilon\n",
        "\treturn c\n",
        "\n",
        "def build_ca_network():\n",
        "\t\"\"\"Builds the conditioning augmentation network.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
        "\tmls = Dense(256)(input_layer1)\n",
        "\tmls = LeakyReLU(alpha=0.2)(mls)\n",
        "\tca = Lambda(conditioning_augmentation)(mls)\n",
        "\treturn Model(inputs=[input_layer1], outputs=[ca])\n"
      ],
      "metadata": {
        "id": "mO-khwzuJmAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def UpSamplingBlock(x, num_kernels):\n",
        "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The preceding layer as input.\n",
        "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
        "\n",
        "\tReturns:\n",
        "\t\tx: The final activation layer after the Upsampling block.\n",
        "\t\"\"\"\n",
        "\tx = UpSampling2D(size=(2,2))(x)\n",
        "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
        "\tx = ReLU()(x)\n",
        "\treturn x\n",
        "\n",
        "\n",
        "def build_stage1_generator():\n",
        "\n",
        "\tinput_layer1 = Input(shape=(1024,))\n",
        "\tca = Dense(256)(input_layer1)\n",
        "\tca = LeakyReLU(alpha=0.2)(ca)\n",
        "\n",
        "\t# Obtain the conditioned text\n",
        "\tc = Lambda(conditioning_augmentation)(ca)\n",
        "\n",
        "\tinput_layer2 = Input(shape=(100,))\n",
        "\tconcat = Concatenate(axis=1)([c, input_layer2])\n",
        "\n",
        "\tx = Dense(16384, use_bias=False)(concat)\n",
        "\tx = ReLU()(x)\n",
        "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
        "\n",
        "\tx = UpSamplingBlock(x, 512)\n",
        "\tx = UpSamplingBlock(x, 256)\n",
        "\tx = UpSamplingBlock(x, 128)\n",
        "\tx = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3\n",
        "\n",
        "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = Activation('tanh')(x)\n",
        "\n",
        "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca])\n",
        "\treturn stage1_gen\n",
        "\n"
      ],
      "metadata": {
        "id": "3jAuZQ3OJoEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
        "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
        "\n",
        "\tArgs:\n",
        "\t\tx: The preceding layer as input.\n",
        "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
        "\n",
        "\tReturns:\n",
        "\t\tx: The final activation layer after the ConvBlock block.\n",
        "\t\"\"\"\n",
        "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\n",
        "\tif activation:\n",
        "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\treturn x\n",
        "\n",
        "\n",
        "def build_embedding_compressor():\n",
        "    \"\"\"Build embedding compressor model\n",
        "    \"\"\"\n",
        "    input_layer1 = Input(shape=(1024,))\n",
        "    x = Dense(128)(input_layer1)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer1], outputs=[x])\n",
        "    return model\n",
        "\n",
        "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
        "def build_stage1_discriminator():\n",
        "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
        "\tand the compressed and spatially replicated embedding.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 1 Discriminator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(64, 64, 3))\n",
        "\n",
        "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
        "\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\tx = ConvBlock(x, 128)\n",
        "\tx = ConvBlock(x, 256)\n",
        "\tx = ConvBlock(x, 512)\n",
        "\n",
        "\t# Obtain the compressed and spatially replicated text embedding\n",
        "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
        "\tconcat = concatenate([x, input_layer2])\n",
        "\n",
        "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
        "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\t# Flatten and add a FC layer to predict.\n",
        "\tx1 = Flatten()(x1)\n",
        "\tx1 = Dense(1)(x1)\n",
        "\tx1 = Activation('sigmoid')(x1)\n",
        "\n",
        "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])\n",
        "\treturn stage1_dis\n"
      ],
      "metadata": {
        "id": "GC3mwbFEJ3Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_stage1_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ95b5RSJ_06",
        "outputId": "8fd39a2d-0feb-4618-d61f-c5a102c07d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 64)   3072        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 32, 32, 64)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 128)  512        ['conv2d_1[0][0]']               \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 4, 4, 512)    2097152     ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            8193        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1)            0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,767,361\n",
            "Trainable params: 2,765,569\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building GAN with Generator and Discriminator\n",
        "\n",
        "def build_adversarial(generator_model, discriminator_model):\n",
        "\t\"\"\"Stage 1 Adversarial model.\n",
        "\n",
        "\tArgs:\n",
        "\t\tgenerator_model: Stage 1 Generator Model\n",
        "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
        "\n",
        "\tReturns:\n",
        "\t\tAdversarial Model.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,))\n",
        "\tinput_layer2 = Input(shape=(100,))\n",
        "\tinput_layer3 = Input(shape=(4, 4, 128))\n",
        "\n",
        "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
        "\n",
        "\tdiscriminator_model.trainable = False\n",
        "\n",
        "\tprobabilities = discriminator_model([x, input_layer3])\n",
        "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
        "\treturn adversarial_model\n",
        "\n"
      ],
      "metadata": {
        "id": "VZBpCMUBKcr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_stage1_generator()"
      ],
      "metadata": {
        "id": "Sdfxu65tNsA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ganstage1 = build_adversarial(generator, discriminator)\n",
        "ganstage1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRXXR0YwKkUF",
        "outputId": "21899b08-6484-423d-8714-b45ce195dec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " model_1 (Functional)           [(None, 64, 64, 3),  10270400    ['input_5[0][0]',                \n",
            "                                 (None, 256)]                     'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 1)            2767361     ['model_1[0][0]',                \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,037,761\n",
            "Trainable params: 10,268,480\n",
            "Non-trainable params: 2,769,281\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint_prefix():\n",
        "\tcheckpoint_dir = './training_checkpoints'\n",
        "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "\n",
        "\treturn checkpoint_prefix\n",
        "\n",
        "def adversarial_loss(y_true, y_pred):\n",
        "\tmean = y_pred[:, :128]\n",
        "\tls = y_pred[:, 128:]\n",
        "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
        "\tloss = K.mean(loss)\n",
        "\treturn loss\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "\tinput_image = (input_image / 127.5) - 1\n",
        "\treal_image = (real_image / 127.5) - 1\n",
        "\n",
        "\treturn input_image, real_image\n",
        "\n",
        "def load_class_ids_filenames(class_id_path, filename_path):\n",
        "\twith open(class_id_path, 'rb') as file:\n",
        "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
        "\n",
        "\twith open(filename_path, 'rb') as file:\n",
        "\t\tfilename = pickle.load(file, encoding='latin1')\n",
        "\n",
        "\treturn class_id, filename\n",
        "\n",
        "def load_text_embeddings(text_embeddings):\n",
        "\twith open(text_embeddings, 'rb') as file:\n",
        "\t\tembeds = pickle.load(file, encoding='latin1')\n",
        "\t\tembeds = np.array(embeds)\n",
        "\n",
        "\treturn embeds\n",
        "\n",
        "def load_bbox(data_path):\n",
        "\tbbox_path = \"/content/drive/MyDrive/CUB_200_2011/CUB_200_2011/bounding_boxes.txt\"\n",
        "\timage_path = \"/content/drive/MyDrive/CUB_200_2011/CUB_200_2011/images.txt\"\n",
        "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
        "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
        "\n",
        "\tfilenames = filename_df[1].tolist()\n",
        "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
        "\n",
        "\tfor i in range(0, len(filenames)):\n",
        "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
        "\t\tdict_key = filenames[i][:-4]\n",
        "\t\tbbox_dict[dict_key] = bbox\n",
        "\n",
        "\treturn bbox_dict\n",
        "\n",
        "def load_images(image_path, bounding_box, size):\n",
        "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
        "\t\"\"\"\n",
        "\timage = Image.open(image_path).convert('RGB')\n",
        "\tw, h = image.size\n",
        "\tif bounding_box is not None:\n",
        "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
        "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
        "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
        "\t\ty1 = np.maximum(0, c_y - r)\n",
        "\t\ty2 = np.minimum(h, c_y + r)\n",
        "\t\tx1 = np.maximum(0, c_x - r)\n",
        "\t\tx2 = np.minimum(w, c_x + r)\n",
        "\t\timage = image.crop([x1, y1, x2, y2])\n",
        "\n",
        "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
        "\treturn image\n",
        "\n",
        "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
        "\t\"\"\"Loads the Dataset.\n",
        "\t\"\"\"\n",
        "\tdata_dir = \"/content/drive/MyDrive/birds\"\n",
        "\ttrain_dir = data_dir + \"/train\"\n",
        "\ttest_dir = data_dir + \"/test\"\n",
        "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
        "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
        "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
        "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
        "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
        "\tdataset_path = \"/content/drive/MyDrive/CUB_200_2011\"\n",
        "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
        "\tembeddings = load_text_embeddings(embeddings_path)\n",
        "\tbbox_dict = load_bbox(dataset_path)\n",
        "\n",
        "\tx, y, embeds = [], [], []\n",
        "\n",
        "\tfor i, filename in enumerate(filenames):\n",
        "\t\tbbox = bbox_dict[filename]\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
        "\t\t\timage = load_images(image_path, bbox, size)\n",
        "\t\t\te = embeddings[i, :, :]\n",
        "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
        "\t\t\tembed = e[embed_index, :]\n",
        "\n",
        "\t\t\tx.append(np.array(image))\n",
        "\t\t\ty.append(class_id[i])\n",
        "\t\t\tembeds.append(embed)\n",
        "\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(f'{e}')\n",
        "\n",
        "\tx = np.array(x)\n",
        "\ty = np.array(y)\n",
        "\tembeds = np.array(embeds)\n",
        "\n",
        "\treturn x, y, embeds\n",
        "\n",
        "def save_image(file, save_path):\n",
        "\t\"\"\"Saves the image at the specified file path.\n",
        "\t\"\"\"\n",
        "\timage = plt.figure()\n",
        "\tax = image.add_subplot(1,1,1)\n",
        "\tax.imshow(file)\n",
        "\tax.axis(\"off\")\n",
        "\tplt.savefig(save_path)"
      ],
      "metadata": {
        "id": "GhM3p1DHPl8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# StackGAN class\n",
        "############################################################\n",
        "\n",
        "class StackGanStage1(object):\n",
        "  \"\"\"StackGAN Stage 1 class.\"\"\"\n",
        "\n",
        "  data_dir = \"/content/drive/MyDrive/birds\"\n",
        "  train_dir = data_dir + \"/train\"\n",
        "  test_dir = data_dir + \"/test\"\n",
        "  embeddings_path_train = \"/content/drive/MyDrive/birds/train/char-CNN-RNN-embeddings.pickle\"\n",
        "  embeddings_path_test = \"/content/drive/MyDrive/birds/test/char-CNN-RNN-embeddings.pickle\"\n",
        "  filename_path_train = \"/content/drive/MyDrive/birds/train/filenames.pickle\"\n",
        "  filename_path_test = \"/content/drive/MyDrive/birds/test/filenames.pickle\"\n",
        "  class_id_path_train = \"/content/drive/MyDrive/birds/train/class_info.pickle\"\n",
        "  class_id_path_test = \"/content/drive/MyDrive/birds/test/class_info.pickle\"\n",
        "  dataset_path = \"/content/drive/MyDrive/CUB_200_2011\"\n",
        "  def __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
        "\t  self.epochs = epochs\n",
        "\t  self.z_dim = z_dim\n",
        "\t  self.enable_function = enable_function\n",
        "\t  self.stage1_generator_lr = stage1_generator_lr\n",
        "\t  self.stage1_discriminator_lr = stage1_discriminator_lr\n",
        "\t  self.image_size = 64\n",
        "\t  self.conditioning_dim = 128\n",
        "\t  self.batch_size = batch_size\n",
        "\n",
        "\t  self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\t  self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "\t  self.stage1_generator = build_stage1_generator()\n",
        "\t  self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
        "\n",
        "\t  self.stage1_discriminator = build_stage1_discriminator()\n",
        "\t  self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
        "\n",
        "\t  self.ca_network = build_ca_network()\n",
        "\t  self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t  self.embedding_compressor = build_embedding_compressor()\n",
        "\t  self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t  self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
        "\t  self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
        "\n",
        "\t  self.checkpoint1 = tf.train.Checkpoint(\n",
        "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
        "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
        "        \tgenerator=self.stage1_generator,\n",
        "        \tdiscriminator=self.stage1_discriminator)\n",
        "\n",
        "  def visualize_stage1(self):\n",
        "\t  \"\"\"Running Tensorboard visualizations.\n",
        "\t\t\"\"\"\n",
        "\t  tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "\t  tb.set_model(self.stage1_generator)\n",
        "\t  tb.set_model(self.stage1_discriminator)\n",
        "\t  tb.set_model(self.ca_network)\n",
        "\t  tb.set_model(self.embedding_compressor)\n",
        "\n",
        "  def train_stage1(self):\n",
        "    \"\"\"Trains the stage1 StackGAN.\"\"\"\n",
        "    filename_path_train = \"/content/drive/MyDrive/birds/train/filenames.pickle\"\n",
        "    x_train, y_train, train_embeds = load_data(filename_path=self.filename_path_train, class_id_path=self.class_id_path_train,\n",
        "                                               dataset_path=self.dataset_path, embeddings_path=self.embeddings_path_train, size=(64, 64))\n",
        "\n",
        "    x_test, y_test, test_embeds = load_data(filename_path=self.filename_path_test, class_id_path=self.class_id_path_test,\n",
        "                                             dataset_path=self.dataset_path, embeddings_path=self.embeddings_path_test, size=(64, 64))\n",
        "\n",
        "    real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
        "    fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "        print(f'Epoch: {epoch}')\n",
        "\n",
        "        gen_loss = []\n",
        "        dis_loss = []\n",
        "\n",
        "        num_batches = int(x_train.shape[0] / self.batch_size)\n",
        "\n",
        "        for i in range(num_batches):\n",
        "\n",
        "            latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "            embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "            compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
        "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
        "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
        "\n",
        "            image_batch = x_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "            image_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "            gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
        "\n",
        "            discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding],\n",
        "                                                                          np.reshape(real, (self.batch_size, 1)))\n",
        "\n",
        "            discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
        "                                                                              np.reshape(fake, (self.batch_size, 1)))\n",
        "\n",
        "            discriminator_loss_wrong = self.stage1_discriminator.train_on_batch(\n",
        "                [gen_images[: self.batch_size - 1], compressed_embedding[1:]],\n",
        "                np.reshape(fake[1:], (self.batch_size - 1, 1)))\n",
        "\n",
        "            # Discriminator loss\n",
        "            d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
        "            dis_loss.append(d_loss)\n",
        "\n",
        "            print(f'Discriminator Loss: {d_loss}')\n",
        "\n",
        "            # Generator loss\n",
        "            g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
        "                                                            [K.ones((self.batch_size, 1)) * 0.9,\n",
        "                                                             K.ones((self.batch_size, 256)) * 0.9])\n",
        "\n",
        "            print(f'Generator Loss: {g_loss}')\n",
        "            gen_loss.append(g_loss)\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "                embedding_batch = test_embeds[0: self.batch_size]\n",
        "                gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
        "\n",
        "                for i, image in enumerate(gen_images[:10]):\n",
        "                    save_image(image, f'test/gen_1_{epoch}_{i}')\n",
        "\n",
        "        if epoch % 25 == 0:\n",
        "            self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
        "            self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n",
        "            self.ca_network.save_weights('weights/stage1_ca.h5')\n",
        "            self.embedding_compressor.save_weights('weights/stage1_embco.h5')\n",
        "            self.stage1_adversarial.save_weights('weights/stage1_adv.h5')\n",
        "\n",
        "    self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
        "    self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n"
      ],
      "metadata": {
        "id": "hXxwFdYDP5U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stage1 = StackGanStage1()\n",
        "stage1.train_stage1()"
      ],
      "metadata": {
        "id": "EmvzkxGPQADB",
        "outputId": "cff2d527-9d94-4e60-d264-b723ff63c31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-34644e9acffb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackGanStage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-8ab83a11db1b>\u001b[0m in \u001b[0;36mtrain_stage1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m\"\"\"Trains the stage1 StackGAN.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfilename_path_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/birds/train/filenames.pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     x_train, y_train, train_embeds = load_data(filename_path=self.filename_path_train, class_id_path=self.class_id_path_train,\n\u001b[0m\u001b[1;32m     65\u001b[0m                                                dataset_path=self.dataset_path, embeddings_path=self.embeddings_path_train, size=(64, 64))\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-80e7f01a7171>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename_path, class_id_path, dataset_path, embeddings_path, size)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_class_ids_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_id_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_text_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mbbox_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-80e7f01a7171>\u001b[0m in \u001b[0;36mload_bbox\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mbbox_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/bounding_boxes.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/images.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mbbox_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mfilename_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6239\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6240\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'has_bill_shape::curved_(up_or_down)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Stage 2 Generator Network\n",
        "############################################################\n",
        "\n",
        "def concat_along_dims(inputs):\n",
        "\t\"\"\"Joins the conditioned text with the encoded image along the dimensions.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinputs: consisting of conditioned text and encoded images as [c,x].\n",
        "\n",
        "\tReturns:\n",
        "\t\tJoint block along the dimensions.\n",
        "\t\"\"\"\n",
        "\tc = inputs[0]\n",
        "\tx = inputs[1]\n",
        "\n",
        "\tc = K.expand_dims(c, axis=1)\n",
        "\tc = K.expand_dims(c, axis=1)\n",
        "\tc = K.tile(c, [1, 16, 16, 1])\n",
        "\treturn K.concatenate([c, x], axis = 3)\n",
        "\n",
        "def residual_block(input):\n",
        "\t\"\"\"Residual block with plain identity connections.\n",
        "\n",
        "\tArgs:\n",
        "\t\tinputs: input layer or an encoded layer\n",
        "\n",
        "\tReturns:\n",
        "\t\tLayer with computed identity mapping.\n",
        "\t\"\"\"\n",
        "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\n",
        "\tx = add([x, input])\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\treturn x\n",
        "\n",
        "def build_stage2_generator():\n",
        "\t\"\"\"Build the Stage 2 Generator Network using the conditioning text and images from stage 1.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Generator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(1024,))\n",
        "\tinput_images = Input(shape=(64, 64, 3))\n",
        "\n",
        "\t# Conditioning Augmentation\n",
        "\tca = Dense(256)(input_layer1)\n",
        "\tmls = LeakyReLU(alpha=0.2)(ca)\n",
        "\tc = Lambda(conditioning_augmentation)(mls)\n",
        "\n",
        "\t# Downsampling block\n",
        "\tx = ZeroPadding2D(padding=(1,1))(input_images)\n",
        "\tx = Conv2D(128, kernel_size=(3,3), strides=1, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
        "\tx = Conv2D(256, kernel_size=(4,4), strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = ZeroPadding2D(padding=(1,1))(x)\n",
        "\tx = Conv2D(512, kernel_size=(4,4), strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\t# Concatenate text conditioning block with the encoded image\n",
        "\tconcat = concat_along_dims([c, x])\n",
        "\n",
        "\t# Residual Blocks\n",
        "\tx = ZeroPadding2D(padding=(1,1))(concat)\n",
        "\tx = Conv2D(512, kernel_size=(3,3), use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\tx = ReLU()(x)\n",
        "\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\tx = residual_block(x)\n",
        "\n",
        "\t# Upsampling Blocks\n",
        "\tx = UpSamplingBlock(x, 512)\n",
        "\tx = UpSamplingBlock(x, 256)\n",
        "\tx = UpSamplingBlock(x, 128)\n",
        "\tx = UpSamplingBlock(x, 64)\n",
        "\n",
        "\tx = Conv2D(3, kernel_size=(3,3), padding='same', use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "\tx = Activation('tanh')(x)\n",
        "\n",
        "\tstage2_gen = Model(inputs=[input_layer1, input_images], outputs=[x, mls])\n",
        "\treturn stage2_gen"
      ],
      "metadata": {
        "id": "KAFSDUDbQDBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_stage2 = build_stage2_generator()\n",
        "generator_stage2.summary()"
      ],
      "metadata": {
        "id": "QxeNo_TrQUC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Stage 2 Discriminator Network\n",
        "############################################################\n",
        "\n",
        "def build_stage2_discriminator():\n",
        "\t\"\"\"Builds the Stage 2 Discriminator that uses the 256x256 resolution images from the generator\n",
        "\tand the compressed and spatially replicated embeddings.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Discriminator Model for StackGAN.\n",
        "\t\"\"\"\n",
        "\tinput_layer1 = Input(shape=(256, 256, 3))\n",
        "\n",
        "\tx = Conv2D(64, kernel_size=(4,4), padding='same', strides=2, use_bias=False,\n",
        "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
        "\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\tx = ConvBlock(x, 128)\n",
        "\tx = ConvBlock(x, 256)\n",
        "\tx = ConvBlock(x, 512)\n",
        "\tx = ConvBlock(x, 1024)\n",
        "\tx = ConvBlock(x, 2048)\n",
        "\tx = ConvBlock(x, 1024, (1,1), 1)\n",
        "\tx = ConvBlock(x, 512, (1,1), 1, False)\n",
        "\n",
        "\tx1 = ConvBlock(x, 128, (1,1), 1)\n",
        "\tx1 = ConvBlock(x1, 128, (3,3), 1)\n",
        "\tx1 = ConvBlock(x1, 512, (3,3), 1, False)\n",
        "\n",
        "\tx2 = add([x, x1])\n",
        "\tx2 = LeakyReLU(alpha=0.2)(x2)\n",
        "\n",
        "\t# Concatenate compressed and spatially replicated embedding\n",
        "\tinput_layer2 = Input(shape=(4, 4, 128))\n",
        "\tconcat = concatenate([x2, input_layer2])\n",
        "\n",
        "\tx3 = Conv2D(512, kernel_size=(1,1), strides=1, padding='same', kernel_initializer='he_uniform')(concat)\n",
        "\tx3 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x3)\n",
        "\tx3 = LeakyReLU(alpha=0.2)(x3)\n",
        "\n",
        "\t# Flatten and add a FC layer\n",
        "\tx3 = Flatten()(x3)\n",
        "\tx3 = Dense(1)(x3)\n",
        "\tx3 = Activation('sigmoid')(x3)\n",
        "\n",
        "\tstage2_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x3])\n",
        "\treturn stage2_dis"
      ],
      "metadata": {
        "id": "UZGSpstnQWuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_stage2 = build_stage2_discriminator()\n",
        "discriminator_stage2.summary()"
      ],
      "metadata": {
        "id": "sp-rcdC7Qdyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Stage 2 Adversarial Model\n",
        "############################################################\n",
        "\n",
        "def stage2_adversarial_network(stage2_disc, stage2_gen, stage1_gen):\n",
        "\t\"\"\"Stage 2 Adversarial Network.\n",
        "\n",
        "\tArgs:\n",
        "\t\tstage2_disc: Stage 2 Discriminator Model.\n",
        "\t\tstage2_gen: Stage 2 Generator Model.\n",
        "\t\tstage1_gen: Stage 1 Generator Model.\n",
        "\n",
        "\tReturns:\n",
        "\t\tStage 2 Adversarial network.\n",
        "\t\"\"\"\n",
        "\tconditioned_embedding = Input(shape=(1024, ))\n",
        "\tlatent_space = Input(shape=(100, ))\n",
        "\tcompressed_replicated = Input(shape=(4, 4, 128))\n",
        "\n",
        "\t#the discriminator is trained separately and stage1_gen already trained, and this is the reason why we freeze its layers by setting the property trainable=false\n",
        "\tinput_images, ca = stage1_gen([conditioned_embedding, latent_space])\n",
        "\tstage2_disc.trainable = False\n",
        "\tstage1_gen.trainable = False\n",
        "\n",
        "\timages, ca2 = stage2_gen([conditioned_embedding, input_images])\n",
        "\tprobability = stage2_disc([images, compressed_replicated])\n",
        "\n",
        "\treturn Model(inputs=[conditioned_embedding, latent_space, compressed_replicated],\n",
        "\t\toutputs=[probability, ca2])"
      ],
      "metadata": {
        "id": "Vpb1IuIeQgUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_stage2 = stage2_adversarial_network(discriminator_stage2, generator_stage2, generator)\n",
        "adversarial_stage2.summary()"
      ],
      "metadata": {
        "id": "RuKmvtfiQlDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StackGanStage2(object):\n",
        "\t\"\"\"StackGAN Stage 2 class.\n",
        "\n",
        "\tArgs:\n",
        "\t\tepochs: Number of epochs\n",
        "\t\tz_dim: Latent space dimensions\n",
        "\t\tbatch_size: Batch Size\n",
        "\t\tenable_function: If True, training function is decorated with tf.function\n",
        "\t\tstage2_generator_lr: Learning rate for stage 2 generator\n",
        "\t\tstage2_discriminator_lr: Learning rate for stage 2 discriminator\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage2_generator_lr=0.0002, stage2_discriminator_lr=0.0002):\n",
        "\t\tself.epochs = epochs\n",
        "\t\tself.z_dim = z_dim\n",
        "\t\tself.enable_function = enable_function\n",
        "\t\tself.stage1_generator_lr = stage2_generator_lr\n",
        "\t\tself.stage1_discriminator_lr = stage2_discriminator_lr\n",
        "\t\tself.low_image_size = 64\n",
        "\t\tself.high_image_size = 256\n",
        "\t\tself.conditioning_dim = 128\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.stage2_generator_optimizer = Adam(lr=stage2_generator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\t\tself.stage2_discriminator_optimizer = Adam(lr=stage2_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "\t\tself.stage1_generator = build_stage1_generator()\n",
        "\t\tself.stage1_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
        "\t\tself.stage1_generator.load_weights('weights/stage1_gen.h5')\n",
        "\t\tself.stage2_generator = build_stage2_generator()\n",
        "\t\tself.stage2_generator.compile(loss='binary_crossentropy', optimizer=self.stage2_generator_optimizer)\n",
        "\n",
        "\t\tself.stage2_discriminator = build_stage2_discriminator()\n",
        "\t\tself.stage2_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage2_discriminator_optimizer)\n",
        "\n",
        "\t\tself.ca_network = build_ca_network()\n",
        "\t\tself.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t\tself.embedding_compressor = build_embedding_compressor()\n",
        "\t\tself.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
        "\n",
        "\t\tself.stage2_adversarial = stage2_adversarial_network(self.stage2_discriminator, self.stage2_generator, self.stage1_generator)\n",
        "\t\tself.stage2_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage2_generator_optimizer)\n",
        "\n",
        "\t\tself.checkpoint2 = tf.train.Checkpoint(\n",
        "        \tgenerator_optimizer=self.stage2_generator_optimizer,\n",
        "        \tdiscriminator_optimizer=self.stage2_discriminator_optimizer,\n",
        "        \tgenerator=self.stage2_generator,\n",
        "        \tdiscriminator=self.stage2_discriminator,\n",
        "        \tgenerator1=self.stage1_generator)\n",
        "\n",
        "\tdef visualize_stage2(self):\n",
        "\t\t\"\"\"Running Tensorboard visualizations.\n",
        "\t\t\"\"\"\n",
        "\t\ttb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
        "\t\ttb.set_model(self.stage2_generator)\n",
        "\t\ttb.set_model(self.stage2_discriminator)\n",
        "\n",
        "\tdef train_stage2(self):\n",
        "\t\t\"\"\"Trains Stage 2 StackGAN.\n",
        "\t\t\"\"\"\n",
        "\t\tx_high_train, y_high_train, high_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(256, 256))\n",
        "\n",
        "\t\tx_high_test, y_high_test, high_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(256, 256))\n",
        "\n",
        "\t\tx_low_train, y_low_train, low_train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
        "\n",
        "\t\tx_low_test, y_low_test, low_test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test,\n",
        "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
        "\n",
        "\t\treal = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
        "\t\tfake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
        "\n",
        "\t\tfor epoch in range(self.epochs):\n",
        "\t\t\tprint(f'Epoch: {epoch}')\n",
        "\n",
        "\t\t\tgen_loss = []\n",
        "\t\t\tdisc_loss = []\n",
        "\n",
        "\t\t\tnum_batches = int(x_high_train.shape[0] / self.batch_size)\n",
        "\n",
        "\t\t\tfor i in range(num_batches):\n",
        "\n",
        "\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "\t\t\t\tembedding_text = high_train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "\t\t\t\tcompressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
        "\t\t\t\tcompressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, self.conditioning_dim))\n",
        "\t\t\t\tcompressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
        "\n",
        "\t\t\t\timage_batch = x_high_train[i * self.batch_size:(i+1) * self.batch_size]\n",
        "\t\t\t\timage_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "\t\t\t\tlow_res_fakes, _ = self.stage1_generator.predict([embedding_text, latent_space], verbose=3)\n",
        "\t\t\t\thigh_res_fakes, _ = self.stage2_generator.predict([embedding_text, low_res_fakes], verbose=3)\n",
        "\n",
        "\t\t\t\tdiscriminator_loss = self.stage2_discriminator.train_on_batch([image_batch, compressed_embedding],\n",
        "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
        "\n",
        "\t\t\t\tdiscriminator_loss_gen = self.stage2_discriminator.train_on_batch([high_res_fakes, compressed_embedding],\n",
        "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
        "\n",
        "\t\t\t\tdiscriminator_loss_fake = self.stage2_discriminator.train_on_batch([image_batch[:(self.batch_size-1)], compressed_embedding[1:]],\n",
        "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size - 1, 1)))\n",
        "\n",
        "\t\t\t\td_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_fake))\n",
        "\t\t\t\tdisc_loss.append(d_loss)\n",
        "\n",
        "\t\t\t\tprint(f'Discriminator Loss: {d_loss}')\n",
        "\n",
        "\t\t\t\tg_loss = self.stage2_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
        "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
        "\t\t\t\tgen_loss.append(g_loss)\n",
        "\n",
        "\t\t\t\tprint(f'Generator Loss: {g_loss}')\n",
        "\n",
        "\t\t\t\tif epoch % 5 == 0:\n",
        "\t\t\t\t\tlatent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
        "\t\t\t\t\tembedding_batch = high_test_embeds[0 : self.batch_size]\n",
        "\n",
        "\t\t\t\t\tlow_fake_images, _ = self.stage1_generator.predict([embedding_batch, latent_space], verbose=3)\n",
        "\t\t\t\t\thigh_fake_images, _ = self.stage2_generator.predict([embedding_batch, low_fake_images], verbose=3)\n",
        "\n",
        "\t\t\t\t\tfor i, image in enumerate(high_fake_images[:10]):\n",
        "\t\t\t\t\t    save_image(image, f'results_stage2/gen_{epoch}_{i}.png')\n",
        "\n",
        "\t\t\t\tif epoch % 10 == 0:\n",
        "\t\t\t\t\tself.stage2_generator.save_weights('weights/stage2_gen.h5')\n",
        "\t\t\t\t\tself.stage2_discriminator.save_weights(\"weights/stage2_disc.h5\")\n",
        "\t\t\t\t\tself.ca_network.save_weights('weights/stage2_ca.h5')\n",
        "\t\t\t\t\tself.embedding_compressor.save_weights('weights/stage2_embco.h5')\n",
        "\t\t\t\t\tself.stage2_adversarial.save_weights('weights/stage2_adv.h5')\n",
        "\n",
        "\t\tself.stage2_generator.save_weights('weights/stage2_gen.h5')\n",
        "\t\tself.stage2_discriminator.save_weights(\"weights/stage2_disc.h5\")"
      ],
      "metadata": {
        "id": "bcCcd2XhQs6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stage2 = StackGanStage2()\n",
        "stage2.train_stage2()"
      ],
      "metadata": {
        "id": "nYJxM9y2QuUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "7674d060-df7a-48e9-81ea-0452e58f42f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0b8f5cbcb1c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstage2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackGanStage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StackGanStage2' is not defined"
          ]
        }
      ]
    }
  ]
}
